{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimizer\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-06-20 21:03:23--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "Resolving archive.ics.uci.edu... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu|128.195.10.249|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10782 (11K) [text/plain]\n",
      "Saving to: ‘wine.data’\n",
      "\n",
      "wine.data           100%[===================>]  10.53K  --.-KB/s    in 0.009s  \n",
      "\n",
      "2017-06-20 21:03:25 (1.16 MB/s) - ‘wine.data’ saved [10782/10782]\n",
      "\n",
      "1,14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065\n",
      "1,13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050\n",
      "1,13.16,2.36,2.67,18.6,101,2.8,3.24,.3,2.81,5.68,1.03,3.17,1185\n",
      "1,14.37,1.95,2.5,16.8,113,3.85,3.49,.24,2.18,7.8,.86,3.45,1480\n",
      "1,13.24,2.59,2.87,21,118,2.8,2.69,.39,1.82,4.32,1.04,2.93,735\n",
      "1,14.2,1.76,2.45,15.2,112,3.27,3.39,.34,1.97,6.75,1.05,2.85,1450\n",
      "1,14.39,1.87,2.45,14.6,96,2.5,2.52,.3,1.98,5.25,1.02,3.58,1290\n",
      "1,14.06,2.15,2.61,17.6,121,2.6,2.51,.31,1.25,5.05,1.06,3.58,1295\n",
      "1,14.83,1.64,2.17,14,97,2.8,2.98,.29,1.98,5.2,1.08,2.85,1045\n",
      "1,13.86,1.35,2.27,16,98,2.98,3.15,.22,1.85,7.22,1.01,3.55,1045\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
    "!head wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x1088762b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/site-packages/xgboost/core.py\", line 324, in __del__\n",
      "    _check_call(_LIB.XGDMatrixFree(self.handle))\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n",
      "/usr/local/lib/python3.5/site-packages/sklearn/gaussian_process/kernels.py:1362: RuntimeWarning: invalid value encountered in true_divide\n",
      "  / np.sqrt(D.sum(2))[:, :, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'eta': 0.08009235180082135, 'n_estimators': 6}\n",
      "0.920838829979\n",
      "{'max_depth': 2, 'eta': 0.07227197516483679, 'n_estimators': 5}\n",
      "0.932704277311\n",
      "{'max_depth': 10, 'eta': 0.9, 'n_estimators': 1}\n",
      "0.932029433911\n",
      "{'max_depth': 9, 'eta': 0.899999999971155, 'n_estimators': 9}\n",
      "0.932029433911\n",
      "{'max_depth': 2, 'eta': 0.8999999462486881, 'n_estimators': 1}\n",
      "0.932612558686\n",
      "{'max_depth': 2, 'eta': 0.9, 'n_estimators': 10}\n",
      "0.932612558686\n",
      "{'max_depth': 10, 'eta': 0.12767619808785438, 'n_estimators': 4}\n",
      "0.926496445653\n",
      "{'max_depth': 5, 'eta': 0.9, 'n_estimators': 1}\n",
      "0.932029433911\n",
      "{'max_depth': 10, 'eta': 0.010000011923919524, 'n_estimators': 9}\n",
      "0.926825952337\n",
      "{'max_depth': 6, 'eta': 0.9, 'n_estimators': 10}\n",
      "0.932029433911\n",
      "{'max_depth': 7, 'eta': 0.01146965714852556, 'n_estimators': 1}\n",
      "0.926825952337\n",
      "{'max_depth': 2, 'eta': 0.899999977203316, 'n_estimators': 2}\n",
      "0.932612558686\n",
      "{'max_depth': 2, 'eta': 0.9, 'n_estimators': 3}\n",
      "0.932612558686\n",
      "{'max_depth': 3, 'eta': 0.01000000000277806, 'n_estimators': 1}\n",
      "0.899571665022\n",
      "{'max_depth': 6, 'eta': 0.8999999441226264, 'n_estimators': 5}\n",
      "0.932029433911\n",
      "{'max_depth': 8, 'eta': 0.9, 'n_estimators': 6}\n",
      "0.932029433911\n",
      "{'max_depth': 7, 'eta': 0.9, 'n_estimators': 2}\n",
      "0.932029433911\n",
      "{'max_depth': 2, 'eta': 0.8999999790145727, 'n_estimators': 8}\n",
      "0.932612558686\n",
      "{'max_depth': 5, 'eta': 0.9, 'n_estimators': 7}\n",
      "0.932029433911\n",
      "{'max_depth': 3, 'eta': 0.9, 'n_estimators': 10}\n",
      "0.926354175043\n",
      "{'max_depth': 10, 'eta': 0.8979430836281828, 'n_estimators': 6}\n",
      "0.932029433911\n",
      "{'max_depth': 7, 'eta': 0.8999999794397859, 'n_estimators': 7}\n",
      "0.932029433911\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('wine.data', header=None, encoding='utf-8', delimiter=',')\n",
    "targets = data.iloc[:,0] - 1  # reindex from 0 for XGBoost\n",
    "features = data.iloc[:,1:]\n",
    "\n",
    "def cross_validate_xgb(features, targets, params, n_splits=2):\n",
    "    k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=23)\n",
    "    param_names = list(params.keys())\n",
    "    results = []\n",
    "    for train, test in k_fold.split(features, targets):\n",
    "        train_data = xgb.DMatrix(data=features.iloc[train].values,\n",
    "                                 label=targets.iloc[train].values)\n",
    "        test_data = xgb.DMatrix(data=features.iloc[test].values,\n",
    "                                label=targets.iloc[test].values)\n",
    "        linear_tree_booster = xgb.train(\n",
    "            params={\n",
    "                'booster': 'gbtree',\n",
    "                'objective': 'multi:softmax',\n",
    "                'num_class': 3,\n",
    "                **params\n",
    "            },\n",
    "            dtrain=train_data,\n",
    "            num_boost_round=25\n",
    "        )\n",
    "        pred = linear_tree_booster.predict(test_data)\n",
    "        results.append(f1_score(test_data.get_label(), pred, average='weighted'))\n",
    "        \n",
    "    return np.mean(results)\n",
    "\n",
    "bo = BayesianOptimizer({\n",
    "    'max_depth': (2, 10),\n",
    "    'n_estimators': (1, 10),\n",
    "    'eta': (.01, .9)\n",
    "},\n",
    "    kernel=Matern(nu=.5)\n",
    ")\n",
    "optimizing = True\n",
    "scores = []\n",
    "for run in range(50):\n",
    "    params = bo.suggest(return_dict=True)\n",
    "    score = cross_validate_xgb(features, targets, params)\n",
    "    print(params)\n",
    "    print(score)\n",
    "    bo.update(list(params.values()), score)\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n",
    "!head breast-cancer-wisconsin.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('breast-cancer-wisconsin.data', header=None, encoding='utf-8', delimiter=',')\n",
    "targets = (data.iloc[:,1] == 'M').astype(int)\n",
    "features = data.iloc[:,1:]\n",
    "\n",
    "def cross_validate_xgb(features, targets, params, n_splits=2):\n",
    "    k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=23)\n",
    "    param_names = list(params.keys())\n",
    "    results = []\n",
    "    for train, test in k_fold.split(features, targets):\n",
    "        train_data = xgb.DMatrix(data=features.iloc[train].values,\n",
    "                                 label=targets.iloc[train].values)\n",
    "        test_data = xgb.DMatrix(data=features.iloc[test].values,\n",
    "                                label=targets.iloc[test].values)\n",
    "        linear_tree_booster = xgb.train(\n",
    "            params={\n",
    "                'booster': 'gbtree',\n",
    "                'objective': 'binary:logistic'\n",
    "                **params\n",
    "            },\n",
    "            dtrain=train_data,\n",
    "            num_boost_round=25\n",
    "        )\n",
    "        pred = linear_tree_booster.predict(test_data)\n",
    "        results.append(roc_auc_score(test_data.get_label(), pred, average='weighted'))\n",
    "        \n",
    "    return np.mean(results)\n",
    "\n",
    "bo = BayesianOptimizer({\n",
    "    'max_depth': (2, 10),\n",
    "    'n_estimators': (1, 10),\n",
    "    'eta': (.01, .9)\n",
    "},\n",
    "    kernel=Matern(nu=.5)\n",
    ")\n",
    "optimizing = True\n",
    "scores = []\n",
    "for run in range(50):\n",
    "    params = bo.suggest(return_dict=True)\n",
    "    score = cross_validate_xgb(features, targets, params)\n",
    "    print(params)\n",
    "    print(score)\n",
    "    bo.update(list(params.values()), score)\n",
    "    scores.append(score)\n",
    "    \n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
